# RQ3: Model Selection - Llama 3.3 70B Instruct (Vertex AI)
# Type: Open source model (70B, no reasoning)

experiment:
  max_cost: 1.0
  enable_autoprompt: False

planner:
  max_rounds: 30
  model: llama-3.3-70b-instruct
  temperature: 1.0
  top_p: 1.0
  max_tokens: 4096
  prompt: ../../dcipher/prompts/base_planner_prompt.yaml
  toolset:
    - run_command
    - submit_flag
    - giveup
    - delegate

executor:
  max_rounds: 100
  model: llama-3.3-70b-instruct
  temperature: 1.0
  top_p: 1.0
  max_tokens: 4096
  len_observations: 5
  prompt: ../../dcipher/prompts/base_executor_prompt.yaml
  toolset:
    - run_command
    - finish_task
    - disassemble
    - decompile
    - create_file

autoprompter:
  max_rounds: 5
  model: llama-3.3-70b-instruct
  temperature: 1.0
  max_tokens: 4096
  prompt: ../../dcipher/prompts/autoprompt_prompt.yaml
  toolset:
    - run_command
    - generate_prompt
